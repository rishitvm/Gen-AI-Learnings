{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae649392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Modules\n",
    "# This code can be taken form Hugging Face\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"andrijdavid/Llama3-2B-Base\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"andrijdavid/Llama-3-2B-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a2120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lists all the layers and internal trainable params list\n",
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f195032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e6166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128256, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Extract the pre-trained weights form the Embedding layer\n",
    "\n",
    "embedding_weights = model.model.embed_tokens.weight.detach().cpu().numpy()\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d78c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 15546, 374, 9734, 266, 34975, 747]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer computes the tokens for given input sequence\n",
    "\n",
    "tokens = tokenizer(\"Who is Virat Kohli\", return_tensors = \"pt\")\n",
    "tokens = tokens['input_ids'].squeeze().tolist()\n",
    "token_length = len(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc87e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbbe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.2969666e-05,  2.5749207e-04, -2.4604797e-04, ...,\n",
       "        -3.2424927e-04, -2.1553040e-04,  4.7111511e-04],\n",
       "       [ 7.5683594e-03, -2.9563904e-04, -1.4190674e-03, ...,\n",
       "         1.7333984e-02,  9.6511841e-04, -6.6223145e-03],\n",
       "       [-2.9907227e-03,  1.6174316e-03,  1.0528564e-03, ...,\n",
       "         9.0942383e-03,  3.9978027e-03,  7.4462891e-03],\n",
       "       ...,\n",
       "       [ 3.9367676e-03,  1.5792847e-03,  8.7738037e-04, ...,\n",
       "         1.2130737e-03,  1.1672974e-03, -4.6386719e-03],\n",
       "       [-1.5319824e-02,  7.2937012e-03, -3.6926270e-03, ...,\n",
       "        -5.4321289e-03, -1.5487671e-03, -1.4038086e-02],\n",
       "       [ 6.4697266e-03, -3.5095215e-03,  1.3793945e-02, ...,\n",
       "         6.3476562e-03,  1.0498047e-02,  8.2397461e-03]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat the token as row number and get the embeddings\n",
    "\n",
    "embeddings = []\n",
    "for x in tokens:\n",
    "    embeddings.append(embedding_weights[x])\n",
    "embeddings = np.stack(embeddings)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b84460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128256, 4096)\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = model.model.embed_tokens.weight.detach().cpu().numpy()\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786353e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4096)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbae1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detach the pre-trained weights for Gamma and Beta params form the layernorm layer\n",
    "\n",
    "layer0 = model.model.layers[0]\n",
    "rms1 = layer0.input_layernorm.weight.detach().cpu().numpy()\n",
    "rms1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c84cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RMS (Root Mean Square) function\n",
    "\n",
    "def rms(token,rms1):\n",
    "    norm_factor = np.sqrt(np.mean(token**2,) + 1e-10)\n",
    "    inter1 = token / norm_factor                           # Normalizes the values\n",
    "    final_op = (inter1)*(rms1)                             # Multiplies with the layer weights\n",
    "    return final_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fece56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.2704086e-04,  7.5706965e-03, -1.5555274e-02, ...,\n",
       "        -3.9163311e-03, -1.3239174e-03,  1.9265389e-03],\n",
       "       [ 4.7919020e-02, -7.2822147e-03, -7.5160660e-02, ...,\n",
       "         1.7539957e-01,  4.9666399e-03, -2.2687687e-02],\n",
       "       [-2.9355817e-02,  6.1764568e-02,  8.6450703e-02, ...,\n",
       "         1.4266199e-01,  3.1894460e-02,  3.9548695e-02],\n",
       "       ...,\n",
       "       [ 3.6865745e-02,  5.7535928e-02,  6.8730973e-02, ...,\n",
       "         1.8154921e-02,  8.8846562e-03, -2.3504503e-02],\n",
       "       [-8.0239147e-02,  1.4861955e-01, -1.6178912e-01, ...,\n",
       "        -4.5470163e-02, -6.5931734e-03, -3.9784566e-02],\n",
       "       [ 5.0012935e-02, -1.0554551e-01,  8.9200288e-01, ...,\n",
       "         7.8421243e-02,  6.5960027e-02,  3.4465492e-02]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms1_output = []\n",
    "for x in embeddings:\n",
    "    rms1_output.append(rms(x,rms1))\n",
    "rms1_output = np.array(rms1_output)\n",
    "rms1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8adf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def trig_multiplication(pair, phi):                       # Definition representing the rotation matrix\n",
    "    x = pair[0]\n",
    "    y = pair[1]\n",
    "    x_new = x * math.cos(phi) - y * math.sin(phi)\n",
    "    y_new = x * math.sin(phi) + y * math.cos(phi)\n",
    "    return [x_new, y_new]\n",
    "\n",
    "def theta(i, dim):                                        # Used in RoPE: Includes the pair value (i) in a continuous value\n",
    "    return pow(10000, (-2 * i) / dim)\n",
    "\n",
    "def phi(position, x):                                     # Used in RoPE: Includes the position\n",
    "    return position * x\n",
    "\n",
    "def RoPE(embedding, position):                            # Divide the Input tensor to pairs then compute the theta -> phi -> rotation for pair\n",
    "    final_rope_values = []\n",
    "    dim = len(embedding)\n",
    "    for i in range(0, dim, 2):\n",
    "        pair = [embedding[i], embedding[i + 1]]\n",
    "        theta_val = theta(i // 2, dim)\n",
    "        phi_val = phi(position, theta_val)\n",
    "        rotated = trig_multiplication(pair, phi_val)\n",
    "        final_rope_values.extend(rotated)\n",
    "    return final_rope_values\n",
    "\n",
    "def add_rope(A):                                          # Adds RoPE to a given matrix\n",
    "    temp = []\n",
    "    for i, x in enumerate(A):\n",
    "        temp.append(RoPE(x, i))\n",
    "    return temp\n",
    "\n",
    "def self_attention(Q, K, V, head_dim):                    # Self Attention which computes softmax(Q.K').V\n",
    "    Q = add_rope(Q)                                       # We include RoPE only to Q and K\n",
    "    K = add_rope(K)\n",
    "    Q = torch.tensor(Q, dtype=torch.float32)\n",
    "    K = torch.tensor(K, dtype=torch.float32)\n",
    "    V = torch.tensor(V, dtype=torch.float32)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(head_dim)\n",
    "    attn = torch.softmax(scores, dim=-1)\n",
    "    out = torch.matmul(attn, V)\n",
    "    return out.numpy()\n",
    "\n",
    "def grouped_multi_query_attention(embeddings, model, layer_idx, group_size, num_heads):\n",
    "    \n",
    "    seq_len, dim = embeddings.shape\n",
    "    head_dim = dim // num_heads\n",
    "    final_attention_output = []\n",
    "\n",
    "    layer = model.model.layers[layer_idx]\n",
    "    w_q_full = layer.self_attn.q_proj.weight.detach().cpu().numpy().T          # Extract the weights form each attention block\n",
    "    w_k_full = layer.self_attn.k_proj.weight.detach().cpu().numpy().T\n",
    "    w_v_full = layer.self_attn.v_proj.weight.detach().cpu().numpy().T\n",
    "    w_o_full = layer.self_attn.o_proj.weight.detach().cpu().numpy().T\n",
    "\n",
    "    q_weights = []\n",
    "    k_weights = []\n",
    "    v_weights = []\n",
    "\n",
    "    for i in range(32):                                                        # Slice them accordingly\n",
    "        q_weights.append(w_q_full[:, i * 128:(i + 1) * 128])\n",
    "\n",
    "    for i in range(8):\n",
    "        k_weights.append(w_k_full[:, i * 128:(i + 1) * 128])\n",
    "        v_weights.append(w_v_full[:, i * 128:(i + 1) * 128])\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(8):\n",
    "        for j in range(4):                                                     # Llama3 2B has 32 heads with 8 groups -> 4 heads in each group\n",
    "            q_proj = embeddings @ q_weights[j + counter]\n",
    "            k_proj = embeddings @ k_weights[i]\n",
    "            v_proj = embeddings @ v_weights[i]\n",
    "            out = self_attention(q_proj, k_proj, v_proj, head_dim)\n",
    "            final_attention_output.append(out)\n",
    "        counter += 4\n",
    "    final_attention_output = np.stack(final_attention_output, axis=1)\n",
    "    final_attention_output = final_attention_output.reshape(seq_len, dim)\n",
    "    final_output = final_attention_output @ w_o_full\n",
    "    final_output = torch.tensor(final_output, dtype=torch.float32)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdd8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the pre-trained weights for projection of self-attention block\n",
    "\n",
    "layer = model.model.layers[0]\n",
    "w_o_full = layer.self_attn.o_proj.weight.detach().cpu().numpy().T\n",
    "w_o_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf7345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4096)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output = np.array(grouped_multi_query_attention(rms1_output, model, 0, 4, 32))\n",
    "new_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc34ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.84000985e-03,  5.44096343e-03, -1.14721125e-02, ...,\n",
       "         2.90262979e-04, -4.43270011e-03,  9.36676515e-05],\n",
       "       [ 4.87546884e-02, -8.19274969e-03, -7.48249590e-02, ...,\n",
       "         1.79154560e-01,  5.12761623e-03, -2.35228650e-02],\n",
       "       [-1.99225582e-02,  7.12517202e-02,  8.75984877e-02, ...,\n",
       "         1.41067356e-01,  3.13803181e-02,  3.93260233e-02],\n",
       "       ...,\n",
       "       [ 3.57237682e-02,  6.00414015e-02,  6.51189983e-02, ...,\n",
       "         2.78638750e-02,  1.32455844e-02, -2.43293326e-02],\n",
       "       [-7.85560757e-02,  1.49450824e-01, -1.66653946e-01, ...,\n",
       "        -4.47310992e-02, -3.03264917e-03, -4.02560011e-02],\n",
       "       [ 4.93738949e-02, -1.06110014e-01,  8.85969758e-01, ...,\n",
       "         8.39299262e-02,  6.64601400e-02,  3.32902148e-02]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add then LayerNorm + GMQA output\n",
    "\n",
    "new_output1 = new_output + rms1_output\n",
    "new_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f29791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00177518,  0.00508267, -0.0052983 , ..., -0.00702702,\n",
       "        -0.0046114 ,  0.00988469],\n",
       "       [ 0.13566115, -0.004889  , -0.02560057, ...,  0.31471696,\n",
       "         0.01729953, -0.11640602],\n",
       "       [-0.08310779,  0.04146636,  0.02944609, ...,  0.25597635,\n",
       "         0.11109307,  0.2029165 ],\n",
       "       ...,\n",
       "       [ 0.10436878,  0.03862741,  0.02341055, ...,  0.03257512,\n",
       "         0.03094655, -0.12059695],\n",
       "       [-0.22716105,  0.09977745, -0.05510721, ..., -0.08158647,\n",
       "        -0.02296499, -0.20412673],\n",
       "       [ 0.14158913, -0.07085919,  0.3038263 , ...,  0.14071012,\n",
       "         0.2297484 ,  0.1768356 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer0 = model.model.layers[0]\n",
    "rms2 = layer0.post_attention_layernorm.weight.detach().cpu().numpy()\n",
    "print(rms2.shape)\n",
    "\n",
    "def rms_final(token, rms_weight):\n",
    "    norm_factor = np.sqrt(np.mean(token**2) + 1e-10)\n",
    "    inter1 = token / norm_factor\n",
    "    final_op = inter1 * rms_weight\n",
    "    return final_op\n",
    "\n",
    "rms2_output = []\n",
    "for x in embeddings:\n",
    "    rms2_output.append(rms_final(x, rms2))\n",
    "rms2_output = np.array(rms2_output)\n",
    "rms2_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f79e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms2_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a Feed Forward Neural Network and it uses 3 weight matrices of mentioned shapes\n",
    "\n",
    "a = layer0.mlp.gate_proj.weight.detach().cpu().numpy().T  # (4096, 11008)\n",
    "b = layer0.mlp.up_proj.weight.detach().cpu().numpy().T    # (4096, 11008)\n",
    "c = layer0.mlp.down_proj.weight.detach().cpu().numpy().T    #(11008, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad118c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00397256,  0.01185522,  0.00321584, ..., -0.03824075,\n",
       "        -0.01792183, -0.00290041],\n",
       "       [ 0.02521166, -0.01358126,  0.00272107, ..., -0.017031  ,\n",
       "        -0.02725086,  0.00742132],\n",
       "       [ 0.02235064, -0.00985271, -0.00957625, ..., -0.08297252,\n",
       "        -0.02208163,  0.01350195],\n",
       "       ...,\n",
       "       [-0.01091908, -0.03957865,  0.01314883, ..., -0.06557581,\n",
       "        -0.00155535,  0.01775776],\n",
       "       [-0.01989701,  0.01341101,  0.01625349, ...,  0.0042439 ,\n",
       "        -0.01207195,  0.01864491],\n",
       "       [ 0.00376212,  0.0092607 ,  0.00027169, ..., -0.02507642,\n",
       "        -0.00829177,  0.01532772]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = rms2_output @ a\n",
    "out3 = rms2_output @ b\n",
    "temp11 = torch.tensor(out1)\n",
    "temp22 = torch.sigmoid(temp11)\n",
    "temp33 = temp11 * temp22\n",
    "temp44 = out3 * np.array(temp33)\n",
    "final1 = temp44 @ c\n",
    "final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af8dd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00574774,  0.01693789, -0.00208246, ..., -0.04526776,\n",
       "        -0.02253323,  0.00698428],\n",
       "       [ 0.16087282, -0.01847026, -0.02287951, ...,  0.29768598,\n",
       "        -0.00995133, -0.1089847 ],\n",
       "       [-0.06075715,  0.03161364,  0.01986984, ...,  0.17300382,\n",
       "         0.08901144,  0.21641845],\n",
       "       ...,\n",
       "       [ 0.0934497 , -0.00095124,  0.03655938, ..., -0.03300069,\n",
       "         0.02939121, -0.10283919],\n",
       "       [-0.24705806,  0.11318845, -0.03885372, ..., -0.07734256,\n",
       "        -0.03503694, -0.18548182],\n",
       "       [ 0.14535126, -0.06159849,  0.30409798, ...,  0.1156337 ,\n",
       "         0.22145663,  0.19216332]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decoder 1 output\n",
    "\n",
    "decoder_output = final1 + rms2_output\n",
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44a4aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n",
      "<class 'transformers.models.llama.modeling_llama.LlamaModel'>\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(type(model.model))\n",
    "print(len(model.model.layers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f48fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.2969666e-05,  2.5749207e-04, -2.4604797e-04, ...,\n",
       "        -3.2424927e-04, -2.1553040e-04,  4.7111511e-04],\n",
       "       [ 7.5683594e-03, -2.9563904e-04, -1.4190674e-03, ...,\n",
       "         1.7333984e-02,  9.6511841e-04, -6.6223145e-03],\n",
       "       [-2.9907227e-03,  1.6174316e-03,  1.0528564e-03, ...,\n",
       "         9.0942383e-03,  3.9978027e-03,  7.4462891e-03],\n",
       "       ...,\n",
       "       [ 3.9367676e-03,  1.5792847e-03,  8.7738037e-04, ...,\n",
       "         1.2130737e-03,  1.1672974e-03, -4.6386719e-03],\n",
       "       [-1.5319824e-02,  7.2937012e-03, -3.6926270e-03, ...,\n",
       "        -5.4321289e-03, -1.5487671e-03, -1.4038086e-02],\n",
       "       [ 6.4697266e-03, -3.5095215e-03,  1.3793945e-02, ...,\n",
       "         6.3476562e-03,  1.0498047e-02,  8.2397461e-03]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_deocder_output = embeddings\n",
    "final_deocder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39db102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_final(token, rms_weight):\n",
    "    norm_factor = np.sqrt(np.mean(token**2) + 1e-10)\n",
    "    inter1 = token / norm_factor\n",
    "    final_op = inter1 * rms_weight\n",
    "    return final_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00370369  0.00315625 -0.01957095 ...  0.00412595 -0.00636029\n",
      "   0.00516023]\n",
      " [ 0.06316976 -0.01191915 -0.06695795 ...  0.16120218  0.0058189\n",
      "  -0.01470037]\n",
      " [-0.01208057  0.05832649  0.08331855 ...  0.03900746 -0.00538583\n",
      "   0.06911729]\n",
      " ...\n",
      " [ 0.04187732  0.03938935  0.05905937 ... -0.0230308   0.00347571\n",
      "  -0.00609357]\n",
      " [-0.08196582  0.16044916 -0.17561598 ... -0.04782964 -0.00976431\n",
      "  -0.01313402]\n",
      " [ 0.07059126 -0.10236117  0.81126344 ...  0.04736836  0.06514798\n",
      "   0.05013653]]\n",
      "[[-0.00893684  0.0155719  -0.02624726 ... -0.01841088 -0.01887543\n",
      "   0.01370269]\n",
      " [ 0.0379235  -0.01832728 -0.01101133 ...  0.1697223  -0.00391575\n",
      "  -0.00086351]\n",
      " [-0.01384858  0.00284412  0.01639566 ...  0.0120878   0.00333951\n",
      "   0.05080814]\n",
      " ...\n",
      " [ 0.02976578  0.01242067  0.02867944 ... -0.07088992 -0.01085001\n",
      "   0.01498003]\n",
      " [-0.05186818  0.06531619 -0.06948203 ... -0.09975584 -0.01028658\n",
      "   0.00146316]\n",
      " [ 0.03568745 -0.06470494  0.30624172 ...  0.0362657   0.02177509\n",
      "   0.0342348 ]]\n",
      "[[ 0.00382217 -0.01196003 -0.03845266 ... -0.06402861 -0.03472065\n",
      "   0.04043813]\n",
      " [ 0.05663998 -0.02623784 -0.0253416  ...  0.23103906 -0.01819616\n",
      "   0.00750952]\n",
      " [ 0.00892558  0.00913132  0.04251982 ... -0.01238042 -0.00921138\n",
      "   0.06632328]\n",
      " ...\n",
      " [ 0.03592689  0.02291754  0.04780825 ... -0.13665998 -0.01737277\n",
      "   0.01764295]\n",
      " [-0.04578826  0.08474613 -0.07012071 ... -0.18408422 -0.02737485\n",
      "   0.02637454]\n",
      " [ 0.04870023 -0.07936969  0.3037186  ...  0.04089619  0.0006073\n",
      "   0.044171  ]]\n",
      "[[-0.03463937  0.00764474 -0.04218842 ... -0.0291345  -0.04218373\n",
      "  -0.00629879]\n",
      " [ 0.08168131 -0.04175822 -0.03524522 ...  0.28103808 -0.0351459\n",
      "  -0.01595815]\n",
      " [-0.0217156   0.02384956  0.02804556 ...  0.01283822 -0.01203816\n",
      "   0.09615104]\n",
      " ...\n",
      " [ 0.01890095  0.06731971  0.07318304 ... -0.10402915 -0.03027348\n",
      "   0.02209752]\n",
      " [-0.09017973  0.12335768 -0.08752698 ... -0.15474239 -0.05158899\n",
      "   0.05648341]\n",
      " [ 0.07578847 -0.07049045  0.40808666 ...  0.07877555  0.01506111\n",
      "   0.02645785]]\n",
      "[[-4.3304581e-02 -8.7139755e-03 -9.6825264e-02 ...  3.8835563e-02\n",
      "  -5.9891589e-02 -4.2654496e-02]\n",
      " [ 6.0612123e-02 -9.1264822e-02 -9.3375921e-02 ...  3.4979129e-01\n",
      "  -2.1756273e-02 -4.7096662e-02]\n",
      " [-2.9552113e-02 -3.1055862e-02  2.3431711e-02 ...  5.8661852e-02\n",
      "  -2.0626279e-02  8.6448468e-02]\n",
      " ...\n",
      " [-1.4347164e-04  5.5743299e-02  5.7027753e-02 ... -7.4062571e-02\n",
      "  -2.9029049e-02  4.2807888e-03]\n",
      " [-1.0424362e-01  1.1601382e-01 -1.2548217e-01 ... -1.5965198e-01\n",
      "  -5.4186899e-02  1.9797102e-02]\n",
      " [ 9.8720640e-02 -1.4545128e-01  4.0962955e-01 ...  7.8658804e-02\n",
      "   5.2829022e-03  8.8162974e-02]]\n",
      "[[-0.08397061  0.01375595 -0.04603558 ... -0.00455476 -0.00077217\n",
      "  -0.10941766]\n",
      " [ 0.02118995 -0.11229853 -0.08035226 ...  0.3861957   0.01962234\n",
      "  -0.10295476]\n",
      " [-0.0758604  -0.01150855 -0.01363534 ...  0.02478196 -0.0554362\n",
      "   0.02456046]\n",
      " ...\n",
      " [-0.03769764  0.09231851  0.0673345  ... -0.11908929 -0.00630704\n",
      "  -0.04158225]\n",
      " [-0.13418853  0.13075794 -0.14415407 ... -0.2183679  -0.06972754\n",
      "  -0.03379166]\n",
      " [ 0.09869295 -0.09452263  0.34193644 ... -0.011717    0.0319374\n",
      "   0.05062286]]\n"
     ]
    }
   ],
   "source": [
    "# Do it for 6 decoders which are present in Llama3 2B model\n",
    "\n",
    "final_decoder_output = embeddings\n",
    "\n",
    "for i in range(6):    \n",
    "    layer0 = model.model.layers[i]\n",
    "    rms1 = layer0.input_layernorm.weight.detach().cpu().numpy()\n",
    "\n",
    "    rms1_output = [rms(x, rms1) for x in final_decoder_output]\n",
    "    rms1_output = np.array(rms1_output)\n",
    "\n",
    "    new_output = np.array(grouped_multi_query_attention(rms1_output, model, i, 4, 32))\n",
    "\n",
    "    new_output1 = new_output + rms1_output\n",
    "\n",
    "    rms2 = layer0.post_attention_layernorm.weight.detach().cpu().numpy()\n",
    "    rms2_output = [rms_final(x, rms2) for x in new_output1]\n",
    "    rms2_output = np.array(rms2_output)\n",
    "\n",
    "    a = layer0.mlp.gate_proj.weight.detach().cpu().numpy().T\n",
    "    b = layer0.mlp.up_proj.weight.detach().cpu().numpy().T\n",
    "    c = layer0.mlp.down_proj.weight.detach().cpu().numpy().T\n",
    "\n",
    "    out1 = rms2_output @ a\n",
    "    out3 = rms2_output @ b\n",
    "    temp22 = 1 / (1 + np.exp(-out1))\n",
    "    temp33 = out1 * temp22\n",
    "    temp44 = out3 * temp33\n",
    "    final1 = temp44 @ c\n",
    "    \n",
    "    decoder_output = final1 + rms2_output\n",
    "    final_decoder_output = decoder_output\n",
    "\n",
    "    print(final_decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3f8e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08397061,  0.01375595, -0.04603558, ..., -0.00455476,\n",
       "        -0.00077217, -0.10941766],\n",
       "       [ 0.02118995, -0.11229853, -0.08035226, ...,  0.3861957 ,\n",
       "         0.01962234, -0.10295476],\n",
       "       [-0.0758604 , -0.01150855, -0.01363534, ...,  0.02478196,\n",
       "        -0.0554362 ,  0.02456046],\n",
       "       ...,\n",
       "       [-0.03769764,  0.09231851,  0.0673345 , ..., -0.11908929,\n",
       "        -0.00630704, -0.04158225],\n",
       "       [-0.13418853,  0.13075794, -0.14415407, ..., -0.2183679 ,\n",
       "        -0.06972754, -0.03379166],\n",
       "       [ 0.09869295, -0.09452263,  0.34193644, ..., -0.011717  ,\n",
       "         0.0319374 ,  0.05062286]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088aa9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 128256)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detach the weights for final Linear Layer used for prediction\n",
    "\n",
    "lm_head_weight = model.lm_head.weight.detach().cpu().numpy().T\n",
    "lm_head_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ba2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the forward Pass\n",
    "\n",
    "logits = final_decoder_output @ lm_head_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f722a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and apply Softmax\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e3b84f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66867, 122747,  76917,  91728, 122749,  14148,  52706],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = softmax(logits)\n",
    "predicted_token_ids = np.argmax(probs, axis=-1)\n",
    "predicted_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ouv', '家伙', '.opensource', 'utilus', 'ysa', '555', 'ylland']\n"
     ]
    }
   ],
   "source": [
    "# Final Output sequence for given text\n",
    "\n",
    "predicted_tokens = tokenizer.batch_decode(predicted_token_ids, skip_special_tokens=True)\n",
    "print(predicted_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46f6593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"andrijdavid/Llama3-2B-Base\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"andrijdavid/Llama-3-2B-Base\")\n",
    "\n",
    "inputs = tokenizer(\"Who is Virat Kohli\", return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "embeddings = model.model.embed_tokens(input_ids)\n",
    "hidden_states = embeddings.transpose(0, 1)\n",
    "layer0 = model.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe9f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m out_after_layer0 \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(out_after_layer0\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:318\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\M Rishit Varma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:256\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    254\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 256\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m    257\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = layer0(hidden_states, None, None, None, False, False, None)\n",
    "\n",
    "out_after_layer0 = out[0].transpose(0, 1)\n",
    "print(out_after_layer0.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
