{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install accelerate peft transformers datasets seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T11:59:26.926979Z","iopub.execute_input":"2025-06-04T11:59:26.927153Z","iopub.status.idle":"2025-06-04T12:00:55.610059Z","shell.execute_reply.started":"2025-06-04T11:59:26.927137Z","shell.execute_reply":"2025-06-04T12:00:55.609308Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=6d32c1fcd12d86bc3038f83e233d54ce3a214bd7ac304ee46a06b89f688500a5\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, seqeval\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 seqeval-1.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load the dataset (This dataset contains NER Tags belonging to Person, Location, Org, Misc)\nfrom datasets import load_dataset\ndataset = load_dataset(\"conll2003\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:01:00.839689Z","iopub.execute_input":"2025-06-04T12:01:00.840289Z","iopub.status.idle":"2025-06-04T12:01:14.503197Z","shell.execute_reply.started":"2025-06-04T12:01:00.840256Z","shell.execute_reply":"2025-06-04T12:01:14.502617Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ed5bc4630649ca916fee43550e1d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab70e31af08f410ba8221b4c125d4ebd"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80891e544ee7442dbb5f2d2aa1050230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06f47feaa7d434dabeb2a4cf293438e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed002ddfb4d46b7a3f919ee30f0b9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408deadf71fd476197a280d7a89c424c"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Sample Data from Train section\ndataset[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:19:35.101149Z","iopub.execute_input":"2025-06-04T12:19:35.101787Z","iopub.status.idle":"2025-06-04T12:19:35.107142Z","shell.execute_reply.started":"2025-06-04T12:19:35.101763Z","shell.execute_reply":"2025-06-04T12:19:35.106468Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Extract the feature names related to NER Tags\n\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\nnum_labels = len(label_list)\nprint(label_list)\nprint(num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:05:43.844129Z","iopub.execute_input":"2025-06-04T12:05:43.844827Z","iopub.status.idle":"2025-06-04T12:05:43.850460Z","shell.execute_reply.started":"2025-06-04T12:05:43.844795Z","shell.execute_reply":"2025-06-04T12:05:43.849599Z"}},"outputs":[{"name":"stdout","text":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n9\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Finetuning Base BERT Model for NER Task","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizerFast\n\n# BERT Tokenizer fetch with Base BERT Model\ntokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:16:46.852805Z","iopub.execute_input":"2025-06-04T12:16:46.853384Z","iopub.status.idle":"2025-06-04T12:16:58.811268Z","shell.execute_reply.started":"2025-06-04T12:16:46.853360Z","shell.execute_reply":"2025-06-04T12:16:58.810667Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b8d0b7336b40a4a97fa127531b3927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68193225a328448091c1abaa615c0861"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae33bf1bbc1543598c0f7b326db5750b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9166eb51d414c3db956e3605b828ee3"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"i like running                  # Input Text\n\ncls i like run ##ing sep        # Tokens by BERT Tokenizer\n\nNone 0 1 2 2 None               # Word Indices\n\n-100 7 7 3 -100 -100            # Ground Labels for Training\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing Definition to get the above cell functionality\n# is_split_into_words = True means the words are being split into sub tokens by BERT\n# Append a huge -ve value for consecutively repeated, CLS, SEP Tokens to not make them participate\n# For others append the respective NER Tag\n\ndef tokenize(example):\n    tokenized_inputs = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    prev_word_idx = None\n    word_ids = tokenized_inputs.word_ids()\n    for word_idx in word_ids:\n        if word_idx is None:\n            labels.append(-100)\n        elif word_idx != prev_word_idx:\n            labels.append(example[\"ner_tags\"][word_idx])\n        else:\n            labels.append(-100)\n        prev_word_idx = word_idx\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n# Map the function to the dataset\ntokenized_dataset = dataset.map(tokenize, batched=)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:25:34.753290Z","iopub.execute_input":"2025-06-04T12:25:34.753550Z","iopub.status.idle":"2025-06-04T12:25:41.964332Z","shell.execute_reply.started":"2025-06-04T12:25:34.753534Z","shell.execute_reply":"2025-06-04T12:25:41.963549Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2fc833120924249b636a43c39c5e50e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a7286ef4634c739505774bd103ab97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97eb8d4cd8664da2a65d25905f3951aa"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from transformers import BertForTokenClassification\n\n# BertForTokenClassification module to get the final layer logits\nmodel = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:27:57.972591Z","iopub.execute_input":"2025-06-04T12:27:57.972916Z","iopub.status.idle":"2025-06-04T12:28:00.454554Z","shell.execute_reply.started":"2025-06-04T12:27:57.972897Z","shell.execute_reply":"2025-06-04T12:28:00.454043Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e0f3b0440484afca1287f0d858df782"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# LoRA Finetuning at Query and Value attention layers\n\nfrom peft import LoraConfig, TaskType, get_peft_model\n\nlora_config = LoraConfig(\n    r = 8,                              # LoRA Rank (d*r, r*d)\n    lora_dropout = 0.1,                 # LoRA Dropout\n    lora_alpha = 32,                    # LoRA Alpha\n    target_modules = [\"query\",\"value\"], # Target Modules\n    bias = \"none\",                      # Bias is set to none\n    task_type = TaskType.TOKEN_CLS,     # Token Classification\n)\n\nmodel = get_peft_model(model, lora_config)    # Apply the LoRA Configurations to the base model\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:31:57.176787Z","iopub.execute_input":"2025-06-04T12:31:57.177066Z","iopub.status.idle":"2025-06-04T12:31:57.217676Z","shell.execute_reply.started":"2025-06-04T12:31:57.177046Z","shell.execute_reply":"2025-06-04T12:31:57.217113Z"}},"outputs":[{"name":"stdout","text":"trainable params: 301,833 || all params: 109,200,402 || trainable%: 0.2764\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:41:03.338553Z","iopub.execute_input":"2025-06-04T12:41:03.339229Z","iopub.status.idle":"2025-06-04T12:41:06.687697Z","shell.execute_reply.started":"2025-06-04T12:41:03.339200Z","shell.execute_reply":"2025-06-04T12:41:06.686956Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\nimport evaluate\n\n# Load the seqeval metric\nseqeval = evaluate.load(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n\n    # Step 1: Take the argmax over the last dimension (convert logits to predicted class indices)\n    predictions = predictions.argmax(-1)\n\n    # Step 2: Initialize containers for the cleaned, label-name-based predictions and labels\n    true_predictions = []\n    true_labels = []\n\n    # Step 3: Iterate over each example in the batch\n    for prediction, label in zip(predictions, labels):\n        sentence_preds = []\n        sentence_labels = []\n\n        # Step 4: Iterate over each token in the sentence\n        for p_token, l_token in zip(prediction, label):\n            if l_token != -100:  # Ignore padding or special tokens\n                sentence_preds.append(label_list[p_token])  # Convert predicted index to label name\n                sentence_labels.append(label_list[l_token])  # Convert true label index to label name\n\n        # Step 5: Add the sentence's prediction and label lists to the batch lists\n        true_predictions.append(sentence_preds)\n        true_labels.append(sentence_labels)\n\n    # Step 6: Compute metrics using seqeval\n    return seqeval.compute(predictions=true_predictions, references=true_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:41:15.419359Z","iopub.execute_input":"2025-06-04T12:41:15.419678Z","iopub.status.idle":"2025-06-04T12:41:16.451267Z","shell.execute_reply.started":"2025-06-04T12:41:15.419631Z","shell.execute_reply":"2025-06-04T12:41:16.450786Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a9d4399628c4358ab92397a6a1e2f49"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Training  Arguments required for Trainer Class\n\ntraining_args = TrainingArguments(\n    output_dir=\"./bert-ner-lora\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=5e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n)\n\n# Data Collator use to make batches\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\n# Trainer class to make the model train\ntrainer = Trainer(\n    model=model,                              # LoRA Finetuned Model\n    args=training_args,                       # Training Arguments\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,                      # BERT Tokenizer\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:41:57.438592Z","iopub.execute_input":"2025-06-04T12:41:57.439377Z","iopub.status.idle":"2025-06-04T12:42:00.111034Z","shell.execute_reply.started":"2025-06-04T12:41:57.439342Z","shell.execute_reply":"2025-06-04T12:42:00.110483Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/570852030.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# WANDB Login for training using API\n\nimport wandb\n\nwandb.login(key=\"***************************************\")\nwandb.init(project=\"bert-ner-lora\", name=\"run-1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:45:50.581180Z","iopub.execute_input":"2025-06-04T12:45:50.581459Z","iopub.status.idle":"2025-06-04T12:45:57.086235Z","shell.execute_reply.started":"2025-06-04T12:45:50.581439Z","shell.execute_reply":"2025-06-04T12:45:57.085581Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">run-1</strong> at: <a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/4whqnyun' target=\"_blank\">https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/4whqnyun</a><br> View project at: <a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora' target=\"_blank\">https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250604_124530-4whqnyun/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250604_124550-vss0hm5f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/vss0hm5f' target=\"_blank\">run-1</a></strong> to <a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora' target=\"_blank\">https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/vss0hm5f' target=\"_blank\">https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/vss0hm5f</a>"},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/m-rishitvarma-vellore-institute-of-technology/bert-ner-lora/runs/vss0hm5f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7b90928a7e10>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Training starts here\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:45:59.557302Z","iopub.execute_input":"2025-06-04T12:45:59.557994Z","iopub.status.idle":"2025-06-04T12:50:58.160013Z","shell.execute_reply.started":"2025-06-04T12:45:59.557968Z","shell.execute_reply":"2025-06-04T12:50:58.159363Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1317/1317 04:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc</th>\n      <th>Misc</th>\n      <th>Org</th>\n      <th>Per</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.060100</td>\n      <td>0.069751</td>\n      <td>{'precision': 0.8868302453680521, 'recall': 0.9640718562874252, 'f1': 0.9238393322900365, 'number': 1837}</td>\n      <td>{'precision': 0.7561837455830389, 'recall': 0.6963123644251626, 'f1': 0.7250141163184641, 'number': 922}</td>\n      <td>{'precision': 0.8081081081081081, 'recall': 0.8918717375093214, 'f1': 0.847926267281106, 'number': 1341}</td>\n      <td>{'precision': 0.9721006564551422, 'recall': 0.9647122692725298, 'f1': 0.9683923705722071, 'number': 1842}</td>\n      <td>0.875203</td>\n      <td>0.906429</td>\n      <td>0.890542</td>\n      <td>0.979615</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.045200</td>\n      <td>0.054185</td>\n      <td>{'precision': 0.9369994660971703, 'recall': 0.9553620032661949, 'f1': 0.9460916442048517, 'number': 1837}</td>\n      <td>{'precision': 0.7984749455337691, 'recall': 0.7950108459869848, 'f1': 0.7967391304347826, 'number': 922}</td>\n      <td>{'precision': 0.8893838158871566, 'recall': 0.8933631618195377, 'f1': 0.8913690476190477, 'number': 1341}</td>\n      <td>{'precision': 0.969551282051282, 'recall': 0.9853420195439739, 'f1': 0.9773828756058157, 'number': 1842}</td>\n      <td>0.915308</td>\n      <td>0.925783</td>\n      <td>0.920515</td>\n      <td>0.984911</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.059000</td>\n      <td>0.050439</td>\n      <td>{'precision': 0.9432851792402355, 'recall': 0.95971692977681, 'f1': 0.9514301133297356, 'number': 1837}</td>\n      <td>{'precision': 0.8004291845493562, 'recall': 0.8091106290672451, 'f1': 0.8047464940668824, 'number': 922}</td>\n      <td>{'precision': 0.8877551020408163, 'recall': 0.9082774049217002, 'f1': 0.8978990047917434, 'number': 1341}</td>\n      <td>{'precision': 0.9746083198271205, 'recall': 0.9793702497285559, 'f1': 0.9769834822637422, 'number': 1842}</td>\n      <td>0.918161</td>\n      <td>0.930831</td>\n      <td>0.924453</td>\n      <td>0.985631</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'precision': 0.8868302453680521, 'recall': 0.9640718562874252, 'f1': 0.9238393322900365, 'number': 1837}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7561837455830389, 'recall': 0.6963123644251626, 'f1': 0.7250141163184641, 'number': 922}\" of type <class 'dict'> for key \"eval/MISC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8081081081081081, 'recall': 0.8918717375093214, 'f1': 0.847926267281106, 'number': 1341}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9721006564551422, 'recall': 0.9647122692725298, 'f1': 0.9683923705722071, 'number': 1842}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nTrainer is attempting to log a value of \"{'precision': 0.9369994660971703, 'recall': 0.9553620032661949, 'f1': 0.9460916442048517, 'number': 1837}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7984749455337691, 'recall': 0.7950108459869848, 'f1': 0.7967391304347826, 'number': 922}\" of type <class 'dict'> for key \"eval/MISC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8893838158871566, 'recall': 0.8933631618195377, 'f1': 0.8913690476190477, 'number': 1341}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.969551282051282, 'recall': 0.9853420195439739, 'f1': 0.9773828756058157, 'number': 1842}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nTrainer is attempting to log a value of \"{'precision': 0.9432851792402355, 'recall': 0.95971692977681, 'f1': 0.9514301133297356, 'number': 1837}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8004291845493562, 'recall': 0.8091106290672451, 'f1': 0.8047464940668824, 'number': 922}\" of type <class 'dict'> for key \"eval/MISC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8877551020408163, 'recall': 0.9082774049217002, 'f1': 0.8978990047917434, 'number': 1341}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9746083198271205, 'recall': 0.9793702497285559, 'f1': 0.9769834822637422, 'number': 1842}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1317, training_loss=0.09569618590147819, metrics={'train_runtime': 298.0475, 'train_samples_per_second': 141.33, 'train_steps_per_second': 4.419, 'total_flos': 1133709322521564.0, 'train_loss': 0.09569618590147819, 'epoch': 3.0})"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"### Inference using Finetuned BERT for NER Task","metadata":{}},{"cell_type":"code","source":"# Save Model and Tokenizer\n\nmodel.save_pretrained(\"./bert-ner-lora-adapters\")\ntokenizer.save_pretrained(\"./bert-ner-lora-adapters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:57:05.393029Z","iopub.execute_input":"2025-06-04T12:57:05.393317Z","iopub.status.idle":"2025-06-04T12:57:05.626736Z","shell.execute_reply.started":"2025-06-04T12:57:05.393296Z","shell.execute_reply":"2025-06-04T12:57:05.626121Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"('./bert-ner-lora-adapters/tokenizer_config.json',\n './bert-ner-lora-adapters/special_tokens_map.json',\n './bert-ner-lora-adapters/vocab.txt',\n './bert-ner-lora-adapters/added_tokens.json',\n './bert-ner-lora-adapters/tokenizer.json')"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# Applying Tokenizer and BertForTokenClassification on the fine - tuned model\n\nfrom transformers import BertForTokenClassification, BertTokenizerFast\n\nmodel_path = \"/kaggle/working/bert-ner-lora-adapters\"\nnum_labels = 9     # Number of NER Classes in Dataset = 9\n\nmodel = BertForTokenClassification.from_pretrained(model_path, num_labels=num_labels)\ntokenizer = BertTokenizerFast.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T12:57:23.731340Z","iopub.execute_input":"2025-06-04T12:57:23.732068Z","iopub.status.idle":"2025-06-04T12:57:24.058289Z","shell.execute_reply.started":"2025-06-04T12:57:23.732043Z","shell.execute_reply":"2025-06-04T12:57:24.057762Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Moving the model to GPU if available\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:18:42.511332Z","iopub.execute_input":"2025-06-04T13:18:42.511655Z","iopub.status.idle":"2025-06-04T13:18:42.522937Z","shell.execute_reply.started":"2025-06-04T13:18:42.511634Z","shell.execute_reply":"2025-06-04T13:18:42.522229Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): ModulesToSaveWrapper(\n    (original_module): Linear(in_features=768, out_features=9, bias=True)\n    (modules_to_save): ModuleDict(\n      (default): Linear(in_features=768, out_features=9, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"# Test Sentence\nsentence = \"EU rejects German call to boycott British lamb.\"\ntokens = tokenizer.tokenize(sentence)\nprint(tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:17:05.615529Z","iopub.execute_input":"2025-06-04T13:17:05.616239Z","iopub.status.idle":"2025-06-04T13:17:05.621321Z","shell.execute_reply.started":"2025-06-04T13:17:05.616216Z","shell.execute_reply":"2025-06-04T13:17:05.620760Z"}},"outputs":[{"name":"stdout","text":"['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# Inference - Forward Pass on the model\n\ninputs = tokenizer(sentence, return_tensors=\"pt\")\ninputs = {k: v.to(device) for k, v in inputs.items()}\noutputs = model(**inputs)\nlogits = outputs.logits\nprint(logits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:19:39.551921Z","iopub.execute_input":"2025-06-04T13:19:39.552229Z","iopub.status.idle":"2025-06-04T13:19:39.706057Z","shell.execute_reply.started":"2025-06-04T13:19:39.552209Z","shell.execute_reply":"2025-06-04T13:19:39.705235Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 6.5184, -2.1567, -5.0326, -0.2609, -3.3490, -0.6522, -4.5866,\n          -1.8128, -4.2013],\n         [-0.0180, -1.0776, -3.2866,  5.2628, -1.7039,  3.9776, -2.3396,\n           0.6239, -3.9333],\n         [ 7.4077, -4.3776, -4.8220, -2.2940, -1.8127, -3.9632, -3.9071,\n          -2.5397, -2.3702],\n         [ 0.5706, -1.6308, -3.9131,  0.7335, -3.2838,  0.7335, -2.9677,\n           6.8644, -0.0675],\n         [ 7.5067, -4.0407, -5.1054, -2.2085, -2.0101, -3.8528, -4.1749,\n          -1.7184, -2.4478],\n         [ 7.8290, -4.0385, -5.0807, -2.3046, -2.2652, -3.8299, -4.1231,\n          -2.4784, -3.0555],\n         [ 7.6783, -3.2521, -4.8373, -1.6185, -2.5400, -3.2518, -4.4885,\n          -1.8913, -3.3188],\n         [ 0.4136, -1.6337, -3.3009,  0.5506, -3.0407,  1.2399, -2.8815,\n           6.6247, -0.5326],\n         [ 6.2841, -3.4898, -4.4371, -2.4205, -0.6604, -3.1009, -2.8188,\n          -2.5737, -2.2779],\n         [ 7.9261, -3.2961, -5.0573, -1.5554, -2.8602, -2.2882, -4.6617,\n          -2.4884, -4.1225],\n         [ 2.9248, -2.5035, -2.8234, -1.4298, -0.7350, -1.4824, -0.7130,\n           0.0824, -0.1084]]], device='cuda:0')\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# Taking the max logit for each token output\n\npredictions = torch.argmax(logits, dim = -1)\npredicted_label_ids = predictions[0].tolist()\nlabel_list = model.config.id2label\npredicted_labels = [label_list[i] for i in predicted_label_ids]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:19:45.330497Z","iopub.execute_input":"2025-06-04T13:19:45.330805Z","iopub.status.idle":"2025-06-04T13:19:45.349448Z","shell.execute_reply.started":"2025-06-04T13:19:45.330784Z","shell.execute_reply":"2025-06-04T13:19:45.348695Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# For reference\n\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\ndict_temp = {}\nflag = 0\nfor x in label_list:\n    dict_temp[x] = flag\n    flag += 1\ndict_temp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:20:16.463726Z","iopub.execute_input":"2025-06-04T13:20:16.464459Z","iopub.status.idle":"2025-06-04T13:20:16.470003Z","shell.execute_reply.started":"2025-06-04T13:20:16.464435Z","shell.execute_reply":"2025-06-04T13:20:16.469260Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"{'O': 0,\n 'B-PER': 1,\n 'I-PER': 2,\n 'B-ORG': 3,\n 'I-ORG': 4,\n 'B-LOC': 5,\n 'I-LOC': 6,\n 'B-MISC': 7,\n 'I-MISC': 8}"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"# Final result and inferenced output\n\ntokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\nfor token, label in zip(tokens, predicted_labels):\n    print(f\"{token:15} -> {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T13:20:55.568243Z","iopub.execute_input":"2025-06-04T13:20:55.569005Z","iopub.status.idle":"2025-06-04T13:20:55.577454Z","shell.execute_reply.started":"2025-06-04T13:20:55.568983Z","shell.execute_reply":"2025-06-04T13:20:55.576711Z"}},"outputs":[{"name":"stdout","text":"[CLS]           -> LABEL_0\neu              -> LABEL_3\nrejects         -> LABEL_0\ngerman          -> LABEL_7\ncall            -> LABEL_0\nto              -> LABEL_0\nboycott         -> LABEL_0\nbritish         -> LABEL_7\nlamb            -> LABEL_0\n.               -> LABEL_0\n[SEP]           -> LABEL_0\n","output_type":"stream"}],"execution_count":77}]}